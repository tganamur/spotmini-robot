![SpotMini](spotmini.png?raw=true "Title")

Overview

Our primary objectives revolved around achieving functionality and adaptability. We implemented precise height control, intricately linked to the system's perception of a predetermined target object. Furthermore, the project endeavors to realize pitch control, grounded in perceptual cues, thereby augmenting the robotic system's dynamic responsiveness. Another is the integration of a closed-loop self-balancing mechanism, utilizing data derived from an Inertial Measurement Unit (IMU). This addition underscores the project's commitment to ensuring the quadruped's stability and adaptability across diverse scenarios. The "brains" of the robot was a Raspberry Pi 4 and the software was written using Python with a ROS stack.

 Key accomplishments include implementing:
 
 1.Height control based on object tracking through computer vision (CV) 
 
 2.Pitch control based on object tracking through computer vision (CV) 

Establishing a balancing feature, positioning us well for future advancements in walking gaits.

Hardware

The model was a 12 DOF robot, meaning that each leg had three joints. We used a Prusa 3D printer to print all the parts and then it was assembled. The open source CAD model was found on thingiverse, a website that hosts different CAD models for various 3D printing projects. The joints are actuated by 996R servos, one for each of the joints. In addition to the CAD model, we also used the realsense camera for perception, as this was a camera we were familiar with using through the labs. We also decided on using the BNO055 IMU as this IMU was tested extensively and used for other projects such as the camera tripod and battleship turret. 

Software

![Software Diagram](software_design_spotmini.png?raw=true "Title")

The software design for our quadruped was based on a ROS stack. We had decided on having one main node that controls and plans the robot movement, and receives information from two sensing nodes, the perception and IMU nodes. The spotmini node had the code to control the servos that made up the joints of the legs. The perception and IMU nodes published their data to topics and the spotmini package uses that to plan and control the robot's movements. In addition, hardware level code was written to acutate the servos using PWM signals generated by the Pi. 
