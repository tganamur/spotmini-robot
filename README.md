This is was a final project for EECS 206A @ UC Berkeley that I worked on with 2 other teammates. 
Overview
Our primary objectives revolved around achieving functionality and adaptability. We implemented precise height control, intricately linked to the system's perception of a predetermined target object. Furthermore, the project endeavors to realize pitch control, grounded in perceptual cues, thereby augmenting the robotic system's dynamic responsiveness. Another is the integration of a closed-loop self-balancing mechanism, utilizing data derived from an Inertial Measurement Unit (IMU). This addition underscores the project's commitment to ensuring the quadruped's stability and adaptability across diverse scenarios. The "brains" of the robot was a Raspberry Pi 4 and the software was written using Python with a ROS stack.
 Key accomplishments include implementing:
 Height control based on object tracking through computer vision (CV) 
 Pitch control based on object tracking through computer vision (CV) 
Establishing a balancing feature, positioning us well for future advancements in walking gaits. 
